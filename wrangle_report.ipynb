{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting: wragle_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This document describes the wrangling process that was undertaken on the wrangle_act notebook. The wrangling process is generally broken down into this main stages which are as follows:<br>\n",
    "- Gather<br>\n",
    "- Access<br>\n",
    "- Clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gather**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we gather anything, we do not have data, then after gathering we have data. So in our case wrangled a dataset from WeRateDogs twitter account. This account  rates people's dogs with a humorous comment about the dog. Data was gathered from different sources. The first source of the data was the twitter archive dataset in csv format sent  to Udacity via email. I gathered this dataset by loading it using the python pandas library. The archive dataset contained basic tweet data (tweet ID, timestamp, text, etc.) for all 5000+ of their tweets as they stood on August 1, 2017. So the dataframe for this dataset was named df_1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second source of the data was gathered through downloading the file programmatical from the web. To do this a python library called requests was used download the tweet image prediction (image_predictions.tsv). The result was table full of image predictions (the top three only) alongside each tweet ID, image URL, and the image number that corresponded to the most confident prediction (numbered 1 to 4 since tweets can have up to four images). To read the the tsv file, pandas was used with the sep attribute set to '\\t' instead of the default '\\c' value. The dataframe for this dataset was named df_2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the twitter archive dataset, retweet count and favorite count were the two of the notable column omissions. To gather this, a twitter API (Application Programming Interfcace) used to load the data was called tweepy. This additional data can be gathered by anyone from Twitter's API. But for progress, since the twitter verification takes a large amount of time, I used the second option were the dataset was provided for us in the classroom. The dataset was in json file format and was saved to (tweet_json.txt). This file was read line by line and it contained a quite number of column. Unfortunately some columns were dropped, because they had less significance to our wrangle process therefore; 'id', 'retweet_count', 'favorite_count' were the only columns kept. The dataframe was saved as 'df3'.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Access**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally this stage comprises of investigating the structure and the properties of a dataset. The datasets were investigated for quality and tidiness issues. This investigation was done using the visual and programmatical methods "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Quality issues - pertain to the content of data. Low quality data is also known as dirty data. There are four dimensions of quality data:<br><br>\n",
    "\n",
    "    - **Completeness:** do we have all of the records that we should? Do we have missing records or not? Are there specific rows, columns, or cells missing?\n",
    "    - **Validity**: we have the records, but they’re not valid, i.e., they don’t conform to a defined schema. A schema is a defined set of rules for data. These rules can be real-world constraints (e.g. negative height is impossible) and table-specific constraints (e.g. unique key constraints in tables).\n",
    "    - **Accuracy**: inaccurate data is wrong data that is valid. It adheres to the defined schema, but it is still incorrect. Example: a patient’s weight that is 5 lbs too heavy because the scale was faulty.\n",
    "    - **Consistency**: inconsistent data is both valid and accurate, but there are multiple correct ways of referring to the same thing. Consistency, i.e., a standard format, in columns that represent the same data across tables and/or within tables is desired."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. tweet_id column should be string data type not integer for df_1.\n",
    "\n",
    "2. timestamp and retweeted_status_timestamp should be datetime not object type for df_1.\n",
    "\n",
    "3. missing values for quite a number of columns for df_1.\n",
    "\n",
    "4. rating_numerator and rating_denominator have invalid and inconsistent data for df_1.\n",
    "\n",
    "5. invalid names like (a, an, the and very) in the name column for df_1.\n",
    "\n",
    "6. column names (p1, p1_ conf, p1_dog, p2, p2_conf, p2_dog, p3, p3_conf, p3_dog) in the image dataframe are not informative for df_2.\n",
    "\n",
    "7.  tweet_id column should be string data type not integer for df_2.\n",
    "\n",
    "8. columns p1, p2 and p3 should be categorical not object for df_2.\n",
    "\n",
    "9. id column in df3 should be string dtype not integer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tidiness issues - pertain to the structure of data. These structural problems generally prevent easy analysis. Untidy data is also known as messy data. The requirements for tidy data are:<br><br>\n",
    "    - Each variable forms a column.\n",
    "    - Each observation forms a row.\n",
    "    - Each type of observational unit forms a table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. for dataframe df_1, (doggo, floofe, pupper, puppo) columns should be categories of a one variable named \"dog_stage\".\n",
    "\n",
    "2. df_1 and df3 should be merged to one dataframe at tweet_id."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clean**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the cleaning stage, all the quality and tidiness issues raised were corrected. The first thing that I did was to create copies of df_1, df_2 and df3. The define-code-test methodology was used. To change tweet_id dtype to string, I used the 'astype' python pandas function set to string. For the timestamp and retweeted_status_timestamp, 'to_datetime' converted these columns to datetime dtype. For missing values, I used the 'dropna' function to drop 'Nan' for the expanded_url column. For rating_numerator and rating_denominator, invalid and inconsistent data were dropped by creating upper and lower boundaries to exclude outliers from the columns. For the name column, I generated a function to extract names from text column. I was able to identify a pattern in the text column, where the function extracted the correct name usually after 'named' or 'name is in the text column. The rows that had \"a\", \"an\", \"the\", \"very\" values in the name column were corrected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For df_2, (p1, p1_ conf, p1_dog, p2, p2_conf, p2_dog, p3, p3_conf, p3_dog) column names were replaced by ('prediction_1', 'confidence_1', 'is_dog_1', 'prediction_2', 'confidence_2', 'is_dog_2','prediction_3', 'confidence_3', 'is_dog_3') respectively. The tweet_id dtype was also converted to string dtype using astype. Columns prediction_1, prediction_2, prediction_3 were set to categorical dtype using astype. Lastly for df3, the id column was set to string dtype using astype."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For tidiness issues, \"dog_stage\" column was created using the (doggo, floofe, pupper, puppo) columns afterwards the columns were dropped. Since df_1 and df3 had related columns, I left joined them with the key columns being 'tweet_id' column for df_1 and 'id' for df3 to remain with two datafames for the analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
